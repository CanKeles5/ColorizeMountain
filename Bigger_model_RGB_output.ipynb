{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bigger-model-RGB-output.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CanKeles5/ColorizeMountainAdversarial/blob/master/Bigger_model_RGB_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtZoTcSLdDxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLTZx77vdyuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data.sampler\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import DataLoader as DL\n",
        "from torch.utils.data import *\n",
        "from PIL import Image, ImageFilter\n",
        "import os\n",
        "import cv2\n",
        "import numpy\n",
        "import random\n",
        "import fnmatch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoFx_B27dyre",
        "colab_type": "code",
        "outputId": "34ce5103-62d2-49e8-99ad-ea2043b8de4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns0BWcxJdymf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir -p ~/.kaggle/\n",
        "! mv kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sZRcsb3dyjk",
        "colab_type": "code",
        "outputId": "5734bc47-c3eb-42a4-ef26-e6c37a0ebe73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "! kaggle datasets download -d puneet6060/intel-image-classification"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading intel-image-classification.zip to /content\n",
            " 96% 331M/346M [00:02<00:00, 102MB/s]\n",
            "100% 346M/346M [00:02<00:00, 126MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ5HD3WUdyhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/intel-image-classification.zip\"\n",
        "to = \"/content/dataset\"\n",
        "! unzip -q -n {path} -d {to}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCsKoNxudyfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_folder = \"/content/dataset/seg_train/seg_train/mountain\"\n",
        "image_paths = []\n",
        "\n",
        "for dirname, _, filenames in os.walk(image_folder):\n",
        "    for filename in filenames:\n",
        "        if(fnmatch.fnmatch(dirname, '*mountain*')):\n",
        "            image_paths.append(os.path.join(dirname, filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_d9BViLdyZ6",
        "colab_type": "code",
        "outputId": "822f4fb2-0aa8-41a8-8688-20e854958031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(image_paths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVzwU8NDdyVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, image_paths, train=True):\n",
        "    self.image_paths = image_paths\n",
        "  \n",
        "  def transforms(self, image):\n",
        "    tfms = transforms.Resize(size=(256, 256))\n",
        "    \n",
        "    tfms = transforms.Compose([\n",
        "                              transforms.Resize(size=(256, 256)),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.RandomRotation(degrees=5),\n",
        "                              transforms.RandomPerspective(distortion_scale=0.05)\n",
        "                              ])\n",
        "\n",
        "    image = tfms(image)\n",
        "    image = image.filter(ImageFilter.MedianFilter())\n",
        "    image = TF.to_tensor(image)\n",
        "    \n",
        "    return image\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = Image.open(self.image_paths[index])\n",
        "    x = self.transforms(image)\n",
        "\n",
        "    return x\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE7VigTSgbdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ValidateSet(Dataset):\n",
        "  def __init__(self, image_paths, train=True):\n",
        "    self.image_paths = image_paths\n",
        "  \n",
        "  def transforms(self, image):\n",
        "    resize = transforms.Resize(size=(256, 256))\n",
        "    image = resize(image)\n",
        "    image = image.filter(ImageFilter.MedianFilter())\n",
        "    image = TF.to_tensor(image)\n",
        "    \n",
        "    return image\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = Image.open(self.image_paths[index])\n",
        "    x = self.transforms(image)\n",
        "\n",
        "    return x\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ibsvoRzdySQ",
        "colab_type": "code",
        "outputId": "3d186da5-ceb3-487d-939b-27afff504bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset = MyDataset(image_paths[0:2500])\n",
        "len(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Q-xSXOgpCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validate_set = ValidateSet(image_paths[2500: 2512])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bqNHcvEdyP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_indices = range(0,2300)\n",
        "test_indices = range(2300, 2500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxjeN-wgdyMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 4\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=SubsetRandomSampler(train_indices))\n",
        "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=SubsetRandomSampler(test_indices))\n",
        "validate_loader = torch.utils.data.DataLoader(validate_set, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnt9_zQypFDD",
        "colab_type": "text"
      },
      "source": [
        "Works with lr=1e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjDfGbTAdyJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def en_double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "\n",
        "def dec_double_conv(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "\n",
        "n=8\n",
        "\n",
        "class G(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dconv_1 = en_double_conv(1, n)\n",
        "        self.dconv_2 = en_double_conv(n, n*2)\n",
        "        self.dconv_3 = en_double_conv(n*2, n*4)\n",
        "        self.dconv_4 = en_double_conv(n*4, n*8)\n",
        "        self.dconv_5 = en_double_conv(n*8, n*8)\n",
        "        self.dconv_6 = en_double_conv(n*8, n*8)\n",
        "        self.dconv_7 = en_double_conv(n*8, n*8)\n",
        "        self.dconv_8 = en_double_conv(n*8, n*8)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.TConv8 = nn.ConvTranspose2d(n*8, n*8, 4, 2, 1)\n",
        "        self.TConv7 = nn.ConvTranspose2d(n*8*2, n*8*2, 4, 2, 1)\n",
        "        self.TConv6 = nn.ConvTranspose2d(n*8*3, n*8*3, 4, 2, 1)\n",
        "        self.TConv5 = nn.ConvTranspose2d(n*8*4, n*8*4, 4, 2, 1)\n",
        "        self.TConv4 = nn.ConvTranspose2d(n*8*5, n*8*5, 4, 2, 1)\n",
        "        self.TConv3 = nn.ConvTranspose2d(n*44, n*44, 4, 2, 1)\n",
        "        self.TConv2 = nn.ConvTranspose2d(n*46, n*46, 4, 2, 1)\n",
        "        self.TConv1 = nn.ConvTranspose2d(n*47, 3, 4, 2, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_1(x)\n",
        "        conv1 = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_2(conv1)\n",
        "        conv2 = self.maxpool(conv2)\n",
        "\n",
        "        conv3 = self.dconv_3(conv2)\n",
        "        conv3 = self.maxpool(conv3)\n",
        "\n",
        "        conv4 = self.dconv_4(conv3)\n",
        "        conv4 = self.maxpool(conv4)\n",
        "\n",
        "        conv5 = self.dconv_5(conv4)\n",
        "        conv5 = self.maxpool(conv5)\n",
        "\n",
        "        conv6 = self.dconv_6(conv5)\n",
        "        conv6 = self.maxpool(conv6)\n",
        "\n",
        "        conv7 = self.dconv_7(conv6)\n",
        "        conv7 = self.maxpool(conv7)\n",
        "\n",
        "        conv8 = self.dconv_8(conv7)\n",
        "        conv8 = self.maxpool(conv8)\n",
        "\n",
        "        x = self.TConv8(conv8)\n",
        "\n",
        "        x = torch.cat([x, conv7], dim=1)\n",
        "        x = self.TConv7(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv6], dim=1)\n",
        "        x = self.TConv6(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv5], dim=1)\n",
        "        x = self.TConv5(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv4], dim=1)\n",
        "        x = self.TConv4(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        x = self.TConv3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "        x = self.TConv2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "        x = self.TConv1(x)\n",
        "        x = nn.Tanh()(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiy9xYOWpBui",
        "colab_type": "text"
      },
      "source": [
        "Works with lr=1e-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNW9WF_aa00g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def en_double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "\n",
        "def dec_double_conv(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "n=8\n",
        "class G2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dconv_1 = en_double_conv(1, n)\n",
        "        self.dconv_2 = en_double_conv(n, n*2)\n",
        "        self.dconv_3 = en_double_conv(n*2, n*4)\n",
        "        self.dconv_4 = en_double_conv(n*4, n*8)\n",
        "        self.dconv_5 = en_double_conv(n*8, n*8)\n",
        "        self.dconv_6 = en_double_conv(n*8, n*8)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.upconv_6 = dec_double_conv(n*8, n*8)\n",
        "        self.upconv_5 = dec_double_conv(n*8*2, n*8*2)\n",
        "        self.upconv_4 = dec_double_conv(n*8*3, n*8*3)\n",
        "        self.upconv_3 = dec_double_conv(n*28, n*28)\n",
        "        self.upconv_2 = dec_double_conv(n*30, n*30)\n",
        "        self.upconv_1 = dec_double_conv(n*31, 3) #maybe dont use this?\n",
        "\n",
        "        self.TConv6 = nn.ConvTranspose2d(n*8, n*8, 4, 2, 1)\n",
        "        self.TConv5 = nn.ConvTranspose2d(n*8*2, n*8*2, 4, 2, 1)\n",
        "        self.TConv4 = nn.ConvTranspose2d(n*8*3, n*8*3, 4, 2, 1)\n",
        "        self.TConv3 = nn.ConvTranspose2d(n*28, n*28, 4, 2, 1)\n",
        "        self.TConv2 = nn.ConvTranspose2d(n*30, n*30, 4, 2, 1)\n",
        "        self.TConv1 = nn.ConvTranspose2d(n*31, n*31, 4, 2, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_1(x)\n",
        "        conv1 = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_2(conv1)\n",
        "        conv2 = self.maxpool(conv2)\n",
        "\n",
        "        conv3 = self.dconv_3(conv2)\n",
        "        conv3 = self.maxpool(conv3)\n",
        "\n",
        "        conv4 = self.dconv_4(conv3)\n",
        "        conv4 = self.maxpool(conv4)\n",
        "\n",
        "        conv5 = self.dconv_5(conv4)\n",
        "        conv5 = self.maxpool(conv5)\n",
        "\n",
        "        conv6 = self.dconv_6(conv5)\n",
        "        conv6 = self.maxpool(conv6)\n",
        "\n",
        "        #x = torch.cat([x, conv6], dim=1)\n",
        "        x = self.TConv6(conv6)\n",
        "        x = self.upconv_6(x)\n",
        "\n",
        "        x = torch.cat([x, conv5], dim=1)\n",
        "        x = self.TConv5(x)\n",
        "        x = self.upconv_5(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv4], dim=1)\n",
        "        x = self.TConv4(x)\n",
        "        x = self.upconv_4(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        x = self.TConv3(x)\n",
        "        x = self.upconv_3(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "        x = self.TConv2(x)\n",
        "        x = self.upconv_2(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "        x = self.TConv1(x)\n",
        "        x = self.upconv_1(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npCGoqrrBcO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def en_double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "\n",
        "def dec_double_conv(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "n=8\n",
        "class G2noPool(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dconv_1 = en_double_conv(1, n)\n",
        "        self.dconv_2 = en_double_conv(n, n*2)\n",
        "        self.dconv_3 = en_double_conv(n*2, n*4)\n",
        "        self.dconv_4 = en_double_conv(n*4, n*8)\n",
        "        self.dconv_5 = en_double_conv(n*8, n*8)\n",
        "        self.dconv_6 = en_double_conv(n*8, n*8)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.upconv_6 = dec_double_conv(n*8, n*8)\n",
        "        self.upconv_5 = dec_double_conv(n*8*2, n*8*2)\n",
        "        self.upconv_4 = dec_double_conv(n*8*3, n*8*3)\n",
        "        self.upconv_3 = dec_double_conv(n*28, n*28)\n",
        "        self.upconv_2 = dec_double_conv(n*30, n*30)\n",
        "        #self.upconv_1 = dec_double_conv(n*31, 3) #maybe dont use this?\n",
        "        self.upconv_1 = nn.Sequential(\n",
        "            nn.Conv2d(n*31, 3, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
        "        )\n",
        "\n",
        "        self.TConv6 = nn.ConvTranspose2d(n*8, n*8, 4, 2, 1)\n",
        "        self.TConv5 = nn.ConvTranspose2d(n*8*2, n*8*2, 4, 2, 1)\n",
        "        self.TConv4 = nn.ConvTranspose2d(n*8*3, n*8*3, 4, 2, 1)\n",
        "        self.TConv3 = nn.ConvTranspose2d(n*28, n*28, 4, 2, 1)\n",
        "        self.TConv2 = nn.ConvTranspose2d(n*30, n*30, 4, 2, 1)\n",
        "        self.TConv1 = nn.ConvTranspose2d(n*31, n*31, 4, 2, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_1(x)\n",
        "        #conv1 = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_2(conv1)\n",
        "        #conv2 = self.maxpool(conv2)\n",
        "\n",
        "        conv3 = self.dconv_3(conv2)\n",
        "        #conv3 = self.maxpool(conv3)\n",
        "\n",
        "        conv4 = self.dconv_4(conv3)\n",
        "        #conv4 = self.maxpool(conv4)\n",
        "\n",
        "        conv5 = self.dconv_5(conv4)\n",
        "        #conv5 = self.maxpool(conv5)\n",
        "\n",
        "        conv6 = self.dconv_6(conv5)\n",
        "        #conv6 = self.maxpool(conv6)\n",
        "\n",
        "        #x = torch.cat([x, conv6], dim=1)\n",
        "        x = self.TConv6(conv6)\n",
        "        x = self.upconv_6(x)\n",
        "\n",
        "        x = torch.cat([x, conv5], dim=1)\n",
        "        x = self.TConv5(x)\n",
        "        x = self.upconv_5(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv4], dim=1)\n",
        "        x = self.TConv4(x)\n",
        "        x = self.upconv_4(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        x = self.TConv3(x)\n",
        "        x = self.upconv_3(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "        x = self.TConv2(x)\n",
        "        x = self.upconv_2(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "        x = self.TConv1(x)\n",
        "        x = self.upconv_1(x)\n",
        "        x = nn.Tanh()(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lYaEuGlo_n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def en_double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "\n",
        "def dec_double_conv(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "n=8\n",
        "class G3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dconv_1 = en_double_conv(1, n)\n",
        "        self.dconv_2 = en_double_conv(n, n*2)\n",
        "        self.dconv_3 = en_double_conv(n*2, n*4)\n",
        "        self.dconv_4 = en_double_conv(n*4, n*8)\n",
        "        self.dconv_5 = en_double_conv(n*8, n*8)\n",
        "        self.dconv_6 = en_double_conv(n*8, n*8)\n",
        "        self.dconv_7 = en_double_conv(n*8, n*8)\n",
        "        #self.dconv_8 = en_double_conv(n*8, n*8)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "        #self.TConv8 = nn.ConvTranspose2d(n*8, n*8, 4, 2, 1)\n",
        "        self.TConv7 = nn.ConvTranspose2d(n*8*2, n*8*2, 4, 2, 1)\n",
        "        self.TConv6 = nn.ConvTranspose2d(n*8*3, n*8*3, 4, 2, 1)\n",
        "        self.TConv5 = nn.ConvTranspose2d(n*8*4, n*8*4, 4, 2, 1)\n",
        "        self.TConv4 = nn.ConvTranspose2d(n*8*5, n*8*5, 4, 2, 1)\n",
        "        self.TConv3 = nn.ConvTranspose2d(n*44, n*44, 4, 2, 1)\n",
        "        self.TConv2 = nn.ConvTranspose2d(n*46, n*46, 4, 2, 1)\n",
        "        self.TConv1 = nn.ConvTranspose2d(n*47, 3, 4, 2, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_1(x)\n",
        "        conv1 = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_2(conv1)\n",
        "        conv2 = self.maxpool(conv2)\n",
        "\n",
        "        conv3 = self.dconv_3(conv2)\n",
        "        conv3 = self.maxpool(conv3)\n",
        "\n",
        "        conv4 = self.dconv_4(conv3)\n",
        "        conv4 = self.maxpool(conv4)\n",
        "\n",
        "        conv5 = self.dconv_5(conv4)\n",
        "        conv5 = self.maxpool(conv5)\n",
        "\n",
        "        conv6 = self.dconv_6(conv5)\n",
        "        conv6 = self.maxpool(conv6)\n",
        "\n",
        "        conv7 = self.dconv_7(conv6)\n",
        "        conv7 = self.maxpool(conv7)\n",
        "\n",
        "        #conv8 = self.dconv_8(conv7)\n",
        "        #conv8 = self.maxpool(conv8)\n",
        "\n",
        "        #x = self.TConv8(conv8)\n",
        "\n",
        "        #x = torch.cat([x, conv7], dim=1)\n",
        "        x = self.TConv7(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv6], dim=1)\n",
        "        x = self.TConv6(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv5], dim=1)\n",
        "        x = self.TConv5(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv4], dim=1)\n",
        "        x = self.TConv4(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        x = self.TConv3(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "        x = self.TConv2(x)\n",
        "        #x = self.dropout(x)\n",
        "\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "        x = self.TConv1(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3UBp8v9dyGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class D(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(D, self).__init__()\n",
        "    self.main = nn.Sequential(        \n",
        "        nn.Conv2d(3, 16, 2, 2, 0), #, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        \n",
        "        nn.Conv2d(16, 32, 2, 2, 0), #, bias=False),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        \n",
        "        nn.Conv2d(32, 64, 2, 2, 0), #, bias=False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        \n",
        "        nn.Conv2d(64, 128, 2, 2, 0), #, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        \n",
        "        nn.Conv2d(128, 256, 2, 2, 0), #, bias=False),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        \n",
        "        nn.Conv2d(256, 512, 2, 2, 0), #, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        \n",
        "        nn.Conv2d(512, 1024, 2, 2, 0), #, bias=False),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(1024, 1, 2, 2, 0), #, bias=False),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "  def forward(self, im):\n",
        "    return self.main(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKjm3piMeMH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generator = G().to(device)\n",
        "Discriminator = D().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ggLijieMFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(0, 0.02)\n",
        "        m.bias.data.normal_(0, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk9qRpM7eMAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_init(Generator)\n",
        "weights_init(Discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHlmD4cGeL98",
        "colab_type": "code",
        "outputId": "22c253fb-754d-45dc-80de-d6b7f30fcda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Number of parameters in Generator: \", sum([p.numel() for p in Generator.parameters()]))\n",
        "print(\"Number of parameters in Discriminator: \", sum([p.numel() for p in Discriminator.parameters()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters in Generator:  8143099\n",
            "Number of parameters in Discriminator:  2805873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aCichf8eL6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "adv_criterion = nn.BCELoss()\n",
        "l1_criterion = nn.L1Loss()\n",
        "G_optim = torch.optim.Adam(Generator.parameters(), lr=6e-6)\n",
        "D_optim = torch.optim.Adam(Discriminator.parameters(), lr=6e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nay_k9-5eYNA",
        "colab_type": "code",
        "outputId": "771fe197-a2c7-4ad1-947f-e861b77d640c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Discriminator.train()\n",
        "Generator.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "G(\n",
              "  (dconv_1): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (dconv_2): Sequential(\n",
              "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (dconv_3): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (dconv_4): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (dconv_5): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (dconv_6): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (dconv_7): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (dconv_8): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (TConv8): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (TConv7): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (TConv6): ConvTranspose2d(192, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (TConv5): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (TConv4): ConvTranspose2d(320, 320, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (TConv3): ConvTranspose2d(352, 352, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (TConv2): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (TConv1): ConvTranspose2d(376, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmUEMf8GeYKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_pic(epoch_no):\n",
        "  Generator.eval()\n",
        "  im = dataset[0]\n",
        "  im = (0.2989*im[0,:,:] + 0.5870*im[1,:,:] + 0.1140*im[2,:,:])\n",
        "  #im = (im[0,:,:] + im[1,:,:] + im[2,:,:])/3\n",
        "  im = im.unsqueeze(0).unsqueeze(0).cuda()\n",
        "  output = Generator(im)\n",
        "  #output = torch.cat([output, im], dim=1)\n",
        "\n",
        "  #output = toRGB(output)\n",
        "\n",
        "  p = output[0].detach().cpu()\n",
        "\n",
        "  p = p.clamp(0.0, 1.0)\n",
        "  \n",
        "  PIL_img = transforms.ToPILImage()(p)\n",
        "  PIL_img = PIL_img.save(str(epoch_no) + \".jpg\")\n",
        "  Generator.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c59g_uLAeYIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_losses_train = []\n",
        "G_losses_train = []\n",
        "\n",
        "D_losses_test = []\n",
        "G_losses_test = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kylWJybMeYBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_data(fake_im, real_im):\n",
        "  batch_size=fake_im.shape[0]\n",
        "  data=torch.cat((fake_im, real_im),dim=0)\n",
        "  labels=torch.cat((torch.zeros(batch_size), torch.ones(batch_size)))\n",
        "  \n",
        "  return data, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBpRwrw_eX9z",
        "colab_type": "code",
        "outputId": "d6faf6e2-9ffc-4290-a885-95b602a1113a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(train_indices))\n",
        "print(len(test_indices))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2300\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EnpDrHleiu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import color\n",
        "import numpy as np\n",
        "\n",
        "def toRGB(img_pt):\n",
        "  img_pt = img_pt.cpu().detach()\n",
        "  res = torch.zeros((4, 3, 256, 256))\n",
        "  for ind in range(img_pt.shape[0]):\n",
        "    pt = img_pt[ind].permute(1, 2, 0)\n",
        "    img_np = pt.numpy()\n",
        "\n",
        "    RGB_image = color.lab2rgb(img_np)\n",
        "    pt = torch.tensor(RGB_image)\n",
        "    pr = pt.permute(2, 1, 0)\n",
        "    res[ind] = torch.tensor(pr)\n",
        "\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZcQKviuej_7",
        "colab_type": "code",
        "outputId": "af245eef-eef8-4968-dd6a-d74f1500c369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "n_epochs = 300\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  D_train_loss = 0.0\n",
        "  G_train_loss = 0.0\n",
        "\n",
        "  D_test_loss = 0.0\n",
        "  G_test_loss = 0.0\n",
        "  for i, real_im in enumerate(train_loader):\n",
        "    gray_scale_im=(0.2989*real_im[:,0,:,:] + 0.5870*real_im[:,1,:,:] + 0.1140*real_im[:,2,:,:])\n",
        "    #gray_scale_im=(real_im[:,0,:,:] + real_im[:,1,:,:] + real_im[:,2,:,:])/3\n",
        "    gray_scale_im=gray_scale_im.unsqueeze(1).to(device)\n",
        "    ##########Train the discriminator##########\n",
        "    D_optim.zero_grad()\n",
        "    real_im=real_im.to(device)\n",
        "    fake_img = Generator(gray_scale_im)\n",
        "    #fake_img = torch.cat([fake_img, gray_scale_im], dim=1)\n",
        "    #fake_img = toRGB(fake_img).to(device)\n",
        "    data, labels = shuffle_data(fake_img, real_im)\n",
        "    guess = Discriminator(data)\n",
        "\n",
        "    D_loss = criterion(guess, labels.to(device))\n",
        "    D_train_loss += D_loss.item()\n",
        "    D_loss.backward()\n",
        "    D_optim.step()\n",
        "    ###########################################\n",
        "    \n",
        "    ############Train the generator############\n",
        "    G_optim.zero_grad()\n",
        "    fake_img = Generator(gray_scale_im)\n",
        "    #fake_img = torch.cat([fake_img, gray_scale_im], dim=1)\n",
        "    #fake_img = toRGB(fake_img).to(device)\n",
        "    guess = Discriminator(fake_img).view(-1)\n",
        "    G_loss_adv = adv_criterion(guess, torch.ones(4).to(device))\n",
        "    G_loss_l1 = l1_criterion(fake_img, real_im.to(device))\n",
        "    G_loss = G_loss_adv + G_loss_l1*100\n",
        "    G_train_loss += G_loss.item()\n",
        "    G_loss.backward()\n",
        "    G_optim.step()\n",
        "    ###########################################\n",
        "    m = i\n",
        "  \n",
        "  for i, real_im in enumerate(test_loader):\n",
        "    real_im=real_im.to(device)\n",
        "    gray_scale_im=(0.2989*real_im[:,0,:,:] + 0.5870*real_im[:,1,:,:] + 0.1140*real_im[:,2,:,:])\n",
        "    #gray_scale_im=(real_im[:,0,:,:] + real_im[:,1,:,:] + real_im[:,2,:,:])/3\n",
        "    gray_scale_im=gray_scale_im.unsqueeze(1).to(device)\n",
        "\n",
        "    fake_img = Generator(gray_scale_im)\n",
        "    #fake_img = torch.cat([fake_img, gray_scale_im], dim=1)\n",
        "    #fake_img = toRGB(fake_img).to(device)\n",
        "    guess = Discriminator(fake_img)\n",
        "    adv_loss = adv_criterion(guess, torch.ones(4).to(device))\n",
        "    l1_loss = l1_criterion(fake_img, real_im)\n",
        "    G_loss = adv_loss + l1_loss*100\n",
        "    G_test_loss += G_loss.item()\n",
        "  \n",
        "  G_train_loss = G_train_loss/len(train_indices)\n",
        "  G_test_loss = G_test_loss/len(test_indices)\n",
        "  print(\"Epoch \" + str(epoch) + \", Train: \" + str(G_train_loss) + \" , Test: \" + str(G_test_loss))\n",
        "  print(\"Number of training examples: \" + str(m))\n",
        "  G_losses_train.append(G_train_loss)\n",
        "  G_losses_test.append(G_test_loss)\n",
        "  save_pic(epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Train: 1.3628993929987367 , Test: 1.3733441996574403\n",
            "Number of training examples: 574\n",
            "Epoch 1, Train: 1.3522508384870446 , Test: 1.3878732228279114\n",
            "Number of training examples: 574\n",
            "Epoch 2, Train: 1.3555391827873562 , Test: 1.397054011821747\n",
            "Number of training examples: 574\n",
            "Epoch 3, Train: 1.3447535197631173 , Test: 1.402616583108902\n",
            "Number of training examples: 574\n",
            "Epoch 4, Train: 1.3476443795535875 , Test: 1.3886151039600372\n",
            "Number of training examples: 574\n",
            "Epoch 5, Train: 1.347688487716343 , Test: 1.3819515705108643\n",
            "Number of training examples: 574\n",
            "Epoch 6, Train: 1.35359236665394 , Test: 1.3599288654327393\n",
            "Number of training examples: 574\n",
            "Epoch 7, Train: 1.3453067491365516 , Test: 1.38200102686882\n",
            "Number of training examples: 574\n",
            "Epoch 8, Train: 1.3501256522925005 , Test: 1.3683269941806793\n",
            "Number of training examples: 574\n",
            "Epoch 9, Train: 1.3457644881372866 , Test: 1.3548831725120545\n",
            "Number of training examples: 574\n",
            "Epoch 10, Train: 1.3413755452114602 , Test: 1.4198902797698976\n",
            "Number of training examples: 574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH5qDRcJej8O",
        "colab_type": "code",
        "outputId": "6ff5b45b-51a3-4d34-8e4a-61ef8c884365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(G_losses_train)\n",
        "plt.plot(G_losses_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f658f1b7e80>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QopEJbYHHoNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_result():\n",
        "  for i, real_im in enumerate(validate_set):\n",
        "      Generator.eval()\n",
        "      r = real_im\n",
        "      real_im = (0.2989*real_im[0,:,:] + 0.5870*real_im[1,:,:] + 0.1140*real_im[2,:,:])\n",
        "      real_im = real_im.unsqueeze(0).unsqueeze(0).cuda()\n",
        "\n",
        "      output = Generator(real_im)\n",
        "      output = output[0].detach().cpu().clamp(0.0, 1.0)\n",
        "\n",
        "      r = transforms.ToPILImage()(real_im)\n",
        "      r = r.save(\"REAL\"+str(i)+\".jpg\")\n",
        "\n",
        "      PIL_img = transforms.ToPILImage()(output)\n",
        "      PIL_img = PIL_img.save(\"RES\"+str(i)+\".jpg\")\n",
        "      Generator.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sibRgwf8JJOa",
        "colab_type": "code",
        "outputId": "e7b0698f-7102-462b-f408-7dab2abbfb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "save_result()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-7cc7914cbfa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-be7fd9b971a4>\u001b[0m in \u001b[0;36msave_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"REAL\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be 2/3 dimensional. Got {} dimensions.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: pic should be 2/3 dimensional. Got 4 dimensions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqpA55P8ej5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def d_save_pic(i):\n",
        "  Generator.eval()\n",
        "  im = real = validate_set[i]\n",
        "  gray_scale = im = (0.2989*im[0,:,:] + 0.5870*im[1,:,:] + 0.1140*im[2,:,:])\n",
        "  #im = (im[0,:,:] + im[1,:,:] + im[2,:,:])/3\n",
        "  im = im.unsqueeze(0).unsqueeze(0).cuda()\n",
        "  \n",
        "  output = Generator(im)\n",
        "  #output = torch.cat([output, im], dim=1)\n",
        "  p = output[0].detach().cpu()\n",
        "  p = p.clamp(0.0, 1.0)\n",
        "  \n",
        "  real_img = transforms.ToPILImage()(real)\n",
        "  real_img = real_img.save(\"real\"+str(i)+\".jpg\")\n",
        "\n",
        "  PIL_img = transforms.ToPILImage()(p)\n",
        "  PIL_img = PIL_img.save(\"res\" + str(i) + \".jpg\")\n",
        "\n",
        "  bw_img = transforms.ToPILImage()(gray_scale)\n",
        "  bw_img = bw_img.save(\"bw\" + str(i) + \".jpg\")\n",
        "\n",
        "  Generator.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_nHYS-mej2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(12):\n",
        "    d_save_pic(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRa_EODnGHIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = \"content\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DFNOkvrG7by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(Generator.state_dict(), G)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8sEwCfgejzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(Discriminator.state_dict(), D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Esd0rwoRmH8",
        "colab_type": "text"
      },
      "source": [
        "#TO-DO:\n",
        "\n",
        "\n",
        "1.   Implement adaptive learning rate.\n",
        "2.   Make the model work with LAB images.\n",
        "3.   See if you overfit, and if you do try data augmentation.\n",
        "4.   Remove all inplace operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvXg751RRx8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}